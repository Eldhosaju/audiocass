# -*- coding: utf-8 -*-
"""webapp using flask.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WQnk4qTTiRyW-yvMs-YauJZjNCnUz9F9
"""



import os
from flask import Flask, flash, request, redirect, url_for, jsonify
from werkzeug.utils import secure_filename
import cv2
import keras
import numpy as np
from keras.models import load_model
from keras import backend as K
 
UPLOAD_FOLDER = './uploads/'
ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg'])
DEBUG = True
app = Flask(__name__)
app.config.from_object(__name__)
app.config['SECRET_KEY'] = '7d441f27d441f27567d441f2b6176a'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
 
def allowed_file(filename):
	return '.' in filename and \
		   filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS
 
@app.route('/', methods=['GET', 'POST'])
def upload_file():
	if request.method == 'POST':
		# check if the post request has the file part
		if 'file' not in request.files:
			flash('No file part')
			return redirect(request.url)
		file = request.files['file']
		if file.filename == '':
			flash('No selected file')
			return redirect(request.url)
		if file and allowed_file(file.filename):
			filename = secure_filename(file.filename)
			file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
			file = "path of the wav file to be tested"

    # load audio file with Librosa
     signal, sample_rate = librosa.load(file, sr=22050)
     data = {
             "mapping": [],
       
             }






hop_length = 512 # in num. of samples
n_fft = 2048 # window in num. of samples
SAMPLE_RATE = 22050
TRACK_DURATION = 7 # measured in seconds
SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION

samples_per_segment = int(SAMPLES_PER_TRACK / 10)
num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)



# calculate start and finish sample for current segment
start = 0
finish = start + samples_per_segment
                    
mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=13, n_fft=n_fft, hop_length=hop_length)
mfcc = mfcc.T

if len(mfcc) == num_mfcc_vectors_per_segment:
      data["mfcc"].append(mfcc.tolist())
                        
z=np.array(data["mfcc"])

z= z[..., np.newaxis]
print(z[0].shape)

   
			
			result = predicter(z[0])
			redirect(url_for('upload_file',filename=filename))
			return '''
			<!doctype html>
			<title>Results</title>
			<h1>The audio is - '''+result+'''</h1>
			
			<form method=post enctype=multipart/form-data>
			  <input type=file name=file>
			  <input type=submit value=Upload>
			</form>
			'''
	return '''
	<!doctype html>
	<title>Upload new File</title>
	<h1>Upload new File</h1>
	<form method=post enctype=multipart/form-data>
	  <input type=file name=file>
	  <input type=submit value=Upload>
	</form>
	'''
 
def predictor(x):
	'''Determines if the image contains a cat or dog'''
	classifier = load_model('model')
  

	res = str(classifier.predict_classes(x, 1, verbose = 0)[0][0])
	print(res)
	
 
	
if __name__ == "__main__":
	app.run()

